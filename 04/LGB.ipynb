{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 피처 엔지니어링\n## 1.데이터 합치기","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/porto-seguro-safe-driver-prediction/'\ntrain = pd.read_csv(data_path + 'train.csv', index_col=\"id\")\ntest = pd.read_csv(data_path + 'test.csv', index_col=\"id\")\nsubmission = pd.read_csv(data_path + 'sample_submission.csv', index_col=\"id\")","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:21:50.477850Z","iopub.execute_input":"2023-10-12T15:21:50.478202Z","iopub.status.idle":"2023-10-12T15:22:04.507877Z","shell.execute_reply.started":"2023-10-12T15:21:50.478175Z","shell.execute_reply":"2023-10-12T15:22:04.506359Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"all_data = pd.concat([train, test], ignore_index=True)\nall_data = all_data.drop(\"target\", axis=1) # 타깃값 제거","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:04.510325Z","iopub.execute_input":"2023-10-12T15:22:04.511074Z","iopub.status.idle":"2023-10-12T15:22:05.130724Z","shell.execute_reply.started":"2023-10-12T15:22:04.511036Z","shell.execute_reply":"2023-10-12T15:22:05.129506Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"all_features = all_data.columns # 전체 피처\nall_features","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:05.132312Z","iopub.execute_input":"2023-10-12T15:22:05.132681Z","iopub.status.idle":"2023-10-12T15:22:05.141619Z","shell.execute_reply.started":"2023-10-12T15:22:05.132652Z","shell.execute_reply":"2023-10-12T15:22:05.140085Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Index(['ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n       'ps_calc_20_bin'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2.명목형 피처 원-핫 인코딩","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncat_features = [feature for feature in all_features if \"cat\" in feature] # 명목형 피처 추출\nonehot_encoder = OneHotEncoder() # 원-핫 인코더 객체 생성\nencoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])\nencoded_cat_matrix","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:05.143838Z","iopub.execute_input":"2023-10-12T15:22:05.145398Z","iopub.status.idle":"2023-10-12T15:22:08.122077Z","shell.execute_reply.started":"2023-10-12T15:22:05.145347Z","shell.execute_reply":"2023-10-12T15:22:08.120703Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<1488028x184 sparse matrix of type '<class 'numpy.float64'>'\n\twith 20832392 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 3.파생 피처 추가","metadata":{}},{"cell_type":"code","source":"# \"데이터 하나당 결측값 개수\"를 파생 피처로 추가\nall_data[\"num_missing\"] = (all_data==-1).sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:08.124878Z","iopub.execute_input":"2023-10-12T15:22:08.125216Z","iopub.status.idle":"2023-10-12T15:22:08.607811Z","shell.execute_reply.started":"2023-10-12T15:22:08.125190Z","shell.execute_reply":"2023-10-12T15:22:08.606744Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 명목형 피처, calc 분류의 피처를 제외한 피처\nremaining_features = [feature for feature in all_features \n                      if (\"cat\" not in feature and \"calc\" not in feature)]\n# num_missing을 remaining_features에 추가\nremaining_features.append(\"num_missing\")","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:08.609688Z","iopub.execute_input":"2023-10-12T15:22:08.610535Z","iopub.status.idle":"2023-10-12T15:22:08.616975Z","shell.execute_reply.started":"2023-10-12T15:22:08.610470Z","shell.execute_reply":"2023-10-12T15:22:08.616116Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 분류가 ind인 피처\nind_features = [feature for feature in all_features if \"ind\" in feature]\nis_first_feature = True\n\nfor ind_feature in ind_features:\n    if is_first_feature:\n        all_data[\"mix_ind\"] = all_data[ind_feature].astype(str) + \"_\"\n        is_first_feature = False\n    else:\n        all_data[\"mix_ind\"] += all_data[ind_feature].astype(str) + \"_\"","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:08.618768Z","iopub.execute_input":"2023-10-12T15:22:08.619585Z","iopub.status.idle":"2023-10-12T15:22:26.735384Z","shell.execute_reply.started":"2023-10-12T15:22:08.619543Z","shell.execute_reply":"2023-10-12T15:22:26.733598Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 명목형 피처의 고윳값별 개수\nall_data[\"ps_ind_02_cat\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:26.737043Z","iopub.execute_input":"2023-10-12T15:22:26.737403Z","iopub.status.idle":"2023-10-12T15:22:26.762815Z","shell.execute_reply.started":"2023-10-12T15:22:26.737376Z","shell.execute_reply":"2023-10-12T15:22:26.761393Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"ps_ind_02_cat\n 1    1079327\n 2     309747\n 3      70172\n 4      28259\n-1        523\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"all_data[\"ps_ind_02_cat\"].value_counts().to_dict()","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:26.764428Z","iopub.execute_input":"2023-10-12T15:22:26.764866Z","iopub.status.idle":"2023-10-12T15:22:26.802865Z","shell.execute_reply.started":"2023-10-12T15:22:26.764836Z","shell.execute_reply":"2023-10-12T15:22:26.801769Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{1: 1079327, 2: 309747, 3: 70172, 4: 28259, -1: 523}"},"metadata":{}}]},{"cell_type":"code","source":"cat_count_features = []\n\nfor feature in cat_features+[\"mix_ind\"]:\n    val_counts_dict = all_data[feature].value_counts().to_dict()\n    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x:val_counts_dict[x])\n    cat_count_features.append(f'{feature}_count')\ncat_count_features","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:26.804599Z","iopub.execute_input":"2023-10-12T15:22:26.805308Z","iopub.status.idle":"2023-10-12T15:22:35.881791Z","shell.execute_reply.started":"2023-10-12T15:22:26.805264Z","shell.execute_reply":"2023-10-12T15:22:35.880548Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['ps_ind_02_cat_count',\n 'ps_ind_04_cat_count',\n 'ps_ind_05_cat_count',\n 'ps_car_01_cat_count',\n 'ps_car_02_cat_count',\n 'ps_car_03_cat_count',\n 'ps_car_04_cat_count',\n 'ps_car_05_cat_count',\n 'ps_car_06_cat_count',\n 'ps_car_07_cat_count',\n 'ps_car_08_cat_count',\n 'ps_car_09_cat_count',\n 'ps_car_10_cat_count',\n 'ps_car_11_cat_count',\n 'mix_ind_count']"},"metadata":{}}]},{"cell_type":"markdown","source":"## 4.필요 없는 피처 제거","metadata":{}},{"cell_type":"code","source":"from scipy import sparse\n\n# 필요 없는 피처들 제거\ndrop_features = [\"ps_ind_14\", \"ps_ind_10_bin\", \"ps_ind_11_bin\", \"ps_ind_12_bin\", \"ps_ind_13_bin\", \"ps_car_14\"]\n# remaining_features, cat_count_features에서 drop_features를 제거한 데이터\nall_data_remaining = all_data[remaining_features+cat_count_features].drop(drop_features, axis=1)\n# 데이터 합치기\nall_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining), encoded_cat_matrix], format=\"csr\")","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:35.883387Z","iopub.execute_input":"2023-10-12T15:22:35.883801Z","iopub.status.idle":"2023-10-12T15:22:39.785264Z","shell.execute_reply.started":"2023-10-12T15:22:35.883767Z","shell.execute_reply":"2023-10-12T15:22:39.783947Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 5.데이터 나누기","metadata":{}},{"cell_type":"code","source":"num_train = len(train)\nX = all_data_sprs[:num_train]\nX_test = all_data_sprs[num_train:]\ny = train[\"target\"].values","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:39.787336Z","iopub.execute_input":"2023-10-12T15:22:39.787832Z","iopub.status.idle":"2023-10-12T15:22:40.769686Z","shell.execute_reply.started":"2023-10-12T15:22:39.787794Z","shell.execute_reply":"2023-10-12T15:22:40.768747Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# 평가지표 계산 함수 작성\n## 1.정규화된 지니계수 계산 함수","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef eval_gini(y_true, y_pred):\n    assert y_true.shape == y_pred.shape\n    n_samples = y_true.shape[0] # 데이터 개수\n    L_mid = np.linspace(1/n_samples, 1, n_samples) # 대각선 값\n    \n    # 1) 예측값에 대한 지니계수\n    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로, y_true 값 정렬\n    L_pred = np.cumsum(pred_order)/np.sum(pred_order) # 로렌츠 곡선\n    G_pred = np.sum(L_mid - L_pred) # 예측값에 대한 지니계수\n    # 2) 예측이 완벽할 때 지니계수\n    true_order = y_true[y_true.argsort()] # y_true 크기순으로, y_true 값 정렬\n    L_true = np.cumsum(true_order)/np.sum(true_order) # 로렌츠 곡선\n    G_true = np.sum(L_mid - L_true) # 예측이 완벽할 때 지니계수\n    # 3) 정규화된 지니계수\n    return G_pred/G_true","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:40.770722Z","iopub.execute_input":"2023-10-12T15:22:40.771867Z","iopub.status.idle":"2023-10-12T15:22:40.780226Z","shell.execute_reply.started":"2023-10-12T15:22:40.771829Z","shell.execute_reply":"2023-10-12T15:22:40.778850Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## 2.LightGBM용 지니계수","metadata":{}},{"cell_type":"code","source":"def gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return \"gini\", eval_gini(labels, preds), True # 반환값","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:40.784994Z","iopub.execute_input":"2023-10-12T15:22:40.786707Z","iopub.status.idle":"2023-10-12T15:22:40.797295Z","shell.execute_reply.started":"2023-10-12T15:22:40.786649Z","shell.execute_reply":"2023-10-12T15:22:40.795766Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 하이퍼파라미터 최적화\n## 1.데이터셋 준비","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\nbayes_dtrain = lgb.Dataset(X_train, y_train)\nbayes_dvalid = lgb.Dataset(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:40.799200Z","iopub.execute_input":"2023-10-12T15:22:40.799588Z","iopub.status.idle":"2023-10-12T15:22:42.276003Z","shell.execute_reply.started":"2023-10-12T15:22:40.799557Z","shell.execute_reply":"2023-10-12T15:22:42.274724Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## 2.하이퍼파라미터 범위 설정","metadata":{}},{"cell_type":"code","source":"# 베이지안 최적화를 위한 하이퍼파라미터 범위\nparam_bounds = {\"num_leaves\": (30, 40),\n                \"lambda_l1\": (0.7, 0.9),\n                \"lambda_l2\": (0.9, 1),\n                \"feature_fraction\": (0.6, 0.7),\n                \"bagging_fraction\": (0.6, 0.9),\n                \"min_child_samples\": (6, 10),\n                \"min_child_weight\": (10, 40)}\n\n# 값이 고정된 하이퍼파라미터\nfixed_params = {\"objective\": \"binary\",\n                \"learning_rate\": 0.005,\n                \"bagging_freq\": 1,\n                \"force_row_wise\": True,\n                \"random_state\": 1991}","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:42.278208Z","iopub.execute_input":"2023-10-12T15:22:42.278663Z","iopub.status.idle":"2023-10-12T15:22:42.286453Z","shell.execute_reply.started":"2023-10-12T15:22:42.278624Z","shell.execute_reply":"2023-10-12T15:22:42.284803Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## 3.(베이지안 최적화용) 평가지표 계산함수 작성","metadata":{}},{"cell_type":"code","source":"def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction, \n                  bagging_fraction, min_child_samples, min_child_weight):\n    '''최적화하려는 평가지표(지니계수) 계산 함수'''\n    # 베이지안 최적화를 수행할 하이퍼파라미터\n    params = {\"num_leaves\": int(round(num_leaves)),\n              \"lambda_l1\": lambda_l1,\n              \"lambda_l2\": lambda_l2,\n              \"feature_fraction\": feature_fraction,\n              \"bagging_fraction\": bagging_fraction,\n              \"min_child_samples\": int(round(min_child_samples)),\n              \"min_child_weight\": min_child_weight,\n              \"feature_pre_filter\": False}\n    params.update(fixed_params) # 고정된 하이퍼파라미터도 추가\n    print(\"하이퍼파라미터:\", params)\n    \n    # LightGBM 모델 훈련\n    lgb_model = lgb.train(params=params,            # 훈련용 하이퍼파라미터\n                         train_set=bayes_dtrain,    # 훈련 데이터셋\n                         num_boost_round=2500,      # 부스팅 반복 횟수\n                         valid_sets=bayes_dvalid,   # 성능 평가용 검증 데이터셋\n                         feval=gini,                # 검증용 평가지표\n                         early_stopping_rounds=300, # 조기종료 조건\n                         verbose_eval=False)        # 100번째마다 점수 출력\n    preds = lgb_model.predict(X_valid) # 검증 데이터로 예측 수행\n    gini_score = eval_gini(y_valid, preds) # 지니계수 계산\n    print(f'지니계수: {gini_score}\\n')\n    \n    return gini_score","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:42.289420Z","iopub.execute_input":"2023-10-12T15:22:42.289976Z","iopub.status.idle":"2023-10-12T15:22:42.307736Z","shell.execute_reply.started":"2023-10-12T15:22:42.289932Z","shell.execute_reply":"2023-10-12T15:22:42.306472Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## 4.최적화 수행","metadata":{}},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\n# 베이지안 최적화 객체 생성\noptimizer = BayesianOptimization(f=eval_function, pbounds=param_bounds, random_state=0)\n# 베이지안 최적화 수행\noptimizer.maximize(init_points=3, n_iter=6)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:22:42.309696Z","iopub.execute_input":"2023-10-12T15:22:42.310107Z","iopub.status.idle":"2023-10-12T15:58:30.483619Z","shell.execute_reply.started":"2023-10-12T15:22:42.310077Z","shell.execute_reply":"2023-10-12T15:58:30.481286Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | min_ch... | min_ch... | num_le... |\n-------------------------------------------------------------------------------------------------------------\n하이퍼파라미터: {'num_leaves': 34, 'lambda_l1': 0.8205526752143287, 'lambda_l2': 0.9544883182996897, 'feature_fraction': 0.6715189366372419, 'bagging_fraction': 0.7646440511781974, 'min_child_samples': 8, 'min_child_weight': 29.376823391999682, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수: 0.2855811556220905\n\n| \u001b[0m1        \u001b[0m | \u001b[0m0.2856   \u001b[0m | \u001b[0m0.7646   \u001b[0m | \u001b[0m0.6715   \u001b[0m | \u001b[0m0.8206   \u001b[0m | \u001b[0m0.9545   \u001b[0m | \u001b[0m7.695    \u001b[0m | \u001b[0m29.38    \u001b[0m | \u001b[0m34.38    \u001b[0m |\n하이퍼파라미터: {'num_leaves': 39, 'lambda_l1': 0.7766883037651555, 'lambda_l2': 0.9791725038082665, 'feature_fraction': 0.6963662760501029, 'bagging_fraction': 0.867531900234624, 'min_child_samples': 8, 'min_child_weight': 27.04133683281797, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수: 0.2837380537005777\n\n| \u001b[0m2        \u001b[0m | \u001b[0m0.2837   \u001b[0m | \u001b[0m0.8675   \u001b[0m | \u001b[0m0.6964   \u001b[0m | \u001b[0m0.7767   \u001b[0m | \u001b[0m0.9792   \u001b[0m | \u001b[0m8.116    \u001b[0m | \u001b[0m27.04    \u001b[0m | \u001b[0m39.26    \u001b[0m |\n하이퍼파라미터: {'num_leaves': 40, 'lambda_l1': 0.7040436794880651, 'lambda_l2': 0.9832619845547939, 'feature_fraction': 0.608712929970154, 'bagging_fraction': 0.6213108174593661, 'min_child_samples': 9, 'min_child_weight': 36.10036444740457, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수: 0.2857848354322048\n\n| \u001b[95m3        \u001b[0m | \u001b[95m0.2858   \u001b[0m | \u001b[95m0.6213   \u001b[0m | \u001b[95m0.6087   \u001b[0m | \u001b[95m0.704    \u001b[0m | \u001b[95m0.9833   \u001b[0m | \u001b[95m9.113    \u001b[0m | \u001b[95m36.1     \u001b[0m | \u001b[95m39.79    \u001b[0m |\n하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.8444997594874222, 'lambda_l2': 0.9234023852202012, 'feature_fraction': 0.6593983245038058, 'bagging_fraction': 0.8977977822397395, 'min_child_samples': 9, 'min_child_weight': 10.549362495448534, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수: 0.2828993761731121\n\n| \u001b[0m4        \u001b[0m | \u001b[0m0.2829   \u001b[0m | \u001b[0m0.8978   \u001b[0m | \u001b[0m0.6594   \u001b[0m | \u001b[0m0.8445   \u001b[0m | \u001b[0m0.9234   \u001b[0m | \u001b[0m8.619    \u001b[0m | \u001b[0m10.55    \u001b[0m | \u001b[0m30.09    \u001b[0m |\n하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.7738449330497988, 'lambda_l2': 0.9032695189818599, 'feature_fraction': 0.6606341064409726, 'bagging_fraction': 0.7666713964943057, 'min_child_samples': 9, 'min_child_weight': 29.306172421380474, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수: 0.28513273331754563\n\n| \u001b[0m5        \u001b[0m | \u001b[0m0.2851   \u001b[0m | \u001b[0m0.7667   \u001b[0m | \u001b[0m0.6606   \u001b[0m | \u001b[0m0.7738   \u001b[0m | \u001b[0m0.9033   \u001b[0m | \u001b[0m8.769    \u001b[0m | \u001b[0m29.31    \u001b[0m | \u001b[0m36.6     \u001b[0m |\n하이퍼파라미터: {'num_leaves': 33, 'lambda_l1': 0.878140825240546, 'lambda_l2': 0.9, 'feature_fraction': 0.6949207801131031, 'bagging_fraction': 0.6580631827594777, 'min_child_samples': 10, 'min_child_weight': 35.85667779964393, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수: 0.28531708475434286\n\n| \u001b[0m6        \u001b[0m | \u001b[0m0.2853   \u001b[0m | \u001b[0m0.6581   \u001b[0m | \u001b[0m0.6949   \u001b[0m | \u001b[0m0.8781   \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m9.826    \u001b[0m | \u001b[0m35.86    \u001b[0m | \u001b[0m32.8     \u001b[0m |\n하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.8433793375135147, 'lambda_l2': 0.9479651949974717, 'feature_fraction': 0.6859622896374784, 'bagging_fraction': 0.8362539818721497, 'min_child_samples': 6, 'min_child_weight': 39.77484183530247, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수: 0.2854766974907317\n\n| \u001b[0m7        \u001b[0m | \u001b[0m0.2855   \u001b[0m | \u001b[0m0.8363   \u001b[0m | \u001b[0m0.686    \u001b[0m | \u001b[0m0.8434   \u001b[0m | \u001b[0m0.948    \u001b[0m | \u001b[0m6.002    \u001b[0m | \u001b[0m39.77    \u001b[0m | \u001b[0m36.8     \u001b[0m |\n하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.7243619242443197, 'lambda_l2': 0.9, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'min_child_samples': 10, 'min_child_weight': 27.951241679061347, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수: 0.28455469364758784\n\n| \u001b[0m8        \u001b[0m | \u001b[0m0.2846   \u001b[0m | \u001b[0m0.6      \u001b[0m | \u001b[0m0.6      \u001b[0m | \u001b[0m0.7244   \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m27.95    \u001b[0m | \u001b[0m30.0     \u001b[0m |\n하이퍼파라미터: {'num_leaves': 36, 'lambda_l1': 0.7, 'lambda_l2': 1.0, 'feature_fraction': 0.7, 'bagging_fraction': 0.9, 'min_child_samples': 6, 'min_child_weight': 33.90131741687068, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수: 0.2840251406982248\n\n| \u001b[0m9        \u001b[0m | \u001b[0m0.284    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.7      \u001b[0m | \u001b[0m0.7      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m33.9     \u001b[0m | \u001b[0m36.05    \u001b[0m |\n=============================================================================================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 5.결과 확인","metadata":{}},{"cell_type":"code","source":"# 평가함수 점수가 최대일 때 하이퍼파라미터\nmax_params = optimizer.max[\"params\"]\nmax_params","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:58:30.487332Z","iopub.execute_input":"2023-10-12T15:58:30.487698Z","iopub.status.idle":"2023-10-12T15:58:30.495561Z","shell.execute_reply.started":"2023-10-12T15:58:30.487670Z","shell.execute_reply":"2023-10-12T15:58:30.494431Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'bagging_fraction': 0.6213108174593661,\n 'feature_fraction': 0.608712929970154,\n 'lambda_l1': 0.7040436794880651,\n 'lambda_l2': 0.9832619845547939,\n 'min_child_samples': 9.112627003799401,\n 'min_child_weight': 36.10036444740457,\n 'num_leaves': 39.78618342232764}"},"metadata":{}}]},{"cell_type":"code","source":"# 정수형 하이퍼파라미터 변환\nmax_params[\"num_leaves\"] = int(round(max_params[\"num_leaves\"]))\nmax_params[\"min_child_samples\"] = int(round(max_params[\"min_child_samples\"]))\n# 값이 고정된 하이퍼파라미터 추가\nmax_params.update(fixed_params)\nmax_params","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:58:30.496935Z","iopub.execute_input":"2023-10-12T15:58:30.497234Z","iopub.status.idle":"2023-10-12T15:58:30.514936Z","shell.execute_reply.started":"2023-10-12T15:58:30.497209Z","shell.execute_reply":"2023-10-12T15:58:30.513260Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'bagging_fraction': 0.6213108174593661,\n 'feature_fraction': 0.608712929970154,\n 'lambda_l1': 0.7040436794880651,\n 'lambda_l2': 0.9832619845547939,\n 'min_child_samples': 9,\n 'min_child_weight': 36.10036444740457,\n 'num_leaves': 40,\n 'objective': 'binary',\n 'learning_rate': 0.005,\n 'bagging_freq': 1,\n 'force_row_wise': True,\n 'random_state': 1991}"},"metadata":{}}]},{"cell_type":"markdown","source":"# 모델 훈련 및 성능 검증\n## 1.최적 하이퍼파라미터를 이용해 LightGBM 훈련","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\n# 층화 K 폴드 교차 검증기\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n# OOF 방식으로 훈련된 모델로, 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_val_preds = np.zeros(X.shape[0])\n# OOF 방식으로 훈련된 모델로, 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_test_preds = np.zeros(X_test.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:58:30.516307Z","iopub.execute_input":"2023-10-12T15:58:30.516628Z","iopub.status.idle":"2023-10-12T15:58:30.539513Z","shell.execute_reply.started":"2023-10-12T15:58:30.516602Z","shell.execute_reply":"2023-10-12T15:58:30.538472Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# OOF 방식으로 모델 훈련, 검증, 예측\nfor idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40) # 각 폴드를 구분하는 문구 출력\n\n    X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n    X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n    dtrain = lgb.Dataset(X_train, y_train)        # LightGBM 전용 훈련 데이터\n    dvalid = lgb.Dataset(X_valid, y_valid)        # LightGBM 전용 검증 데이터\n\n    # LightGBM 모델 훈련\n    lgb_model = lgb.train(params=max_params,         # 최적 하이퍼파라미터\n                          train_set=dtrain,          # 훈련 데이터셋\n                          num_boost_round=2500,      # 부스팅 반복 횟수\n                          valid_sets=dvalid,         # 성능 평가용 검증 데이터셋\n                          feval=gini,                # 검증용 평가지표\n                          early_stopping_rounds=300, # 조기종료 조건\n                          verbose_eval=100)          # 100번째마다 점수 출력\n    \n    # 테스트 데이터를 활용해 OOF 예측\n    oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n    print(f'폴드 {idx+1} 지니계수: {gini_score}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:58:30.540847Z","iopub.execute_input":"2023-10-12T15:58:30.541238Z","iopub.status.idle":"2023-10-12T16:26:15.041865Z","shell.execute_reply.started":"2023-10-12T15:58:30.541204Z","shell.execute_reply":"2023-10-12T16:26:15.040030Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"######################################## 폴드 1 / 폴드 5 ########################################\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 17355, number of negative: 458814\n[LightGBM] [Info] Total Bins 1554\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 216\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274764\n[LightGBM] [Info] Start training from score -3.274764\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.154239\tvalid_0's gini: 0.270944\n[200]\tvalid_0's binary_logloss: 0.153176\tvalid_0's gini: 0.275764\n[300]\tvalid_0's binary_logloss: 0.152584\tvalid_0's gini: 0.279501\n[400]\tvalid_0's binary_logloss: 0.152222\tvalid_0's gini: 0.282893\n[500]\tvalid_0's binary_logloss: 0.151986\tvalid_0's gini: 0.286058\n[600]\tvalid_0's binary_logloss: 0.151824\tvalid_0's gini: 0.288805\n[700]\tvalid_0's binary_logloss: 0.151712\tvalid_0's gini: 0.290719\n[800]\tvalid_0's binary_logloss: 0.151622\tvalid_0's gini: 0.292581\n[900]\tvalid_0's binary_logloss: 0.151552\tvalid_0's gini: 0.294212\n[1000]\tvalid_0's binary_logloss: 0.151505\tvalid_0's gini: 0.295204\n[1100]\tvalid_0's binary_logloss: 0.151471\tvalid_0's gini: 0.295909\n[1200]\tvalid_0's binary_logloss: 0.151438\tvalid_0's gini: 0.296721\n[1300]\tvalid_0's binary_logloss: 0.151414\tvalid_0's gini: 0.297335\n[1400]\tvalid_0's binary_logloss: 0.151402\tvalid_0's gini: 0.297569\n[1500]\tvalid_0's binary_logloss: 0.15139\tvalid_0's gini: 0.297881\n[1600]\tvalid_0's binary_logloss: 0.151382\tvalid_0's gini: 0.298033\n[1700]\tvalid_0's binary_logloss: 0.151376\tvalid_0's gini: 0.298238\n[1800]\tvalid_0's binary_logloss: 0.151372\tvalid_0's gini: 0.298342\n[1900]\tvalid_0's binary_logloss: 0.151369\tvalid_0's gini: 0.298371\n[2000]\tvalid_0's binary_logloss: 0.151371\tvalid_0's gini: 0.298222\n[2100]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.298463\n[2200]\tvalid_0's binary_logloss: 0.151359\tvalid_0's gini: 0.298466\n[2300]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.298415\n[2400]\tvalid_0's binary_logloss: 0.151359\tvalid_0's gini: 0.298569\n[2500]\tvalid_0's binary_logloss: 0.151361\tvalid_0's gini: 0.298542\nDid not meet early stopping. Best iteration is:\n[2458]\tvalid_0's binary_logloss: 0.151355\tvalid_0's gini: 0.29865\n폴드 1 지니계수: 0.2986504843987991\n\n######################################## 폴드 2 / 폴드 5 ########################################\n[LightGBM] [Info] Number of positive: 17355, number of negative: 458814\n[LightGBM] [Info] Total Bins 1560\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 216\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274764\n[LightGBM] [Info] Start training from score -3.274764\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.154347\tvalid_0's gini: 0.258575\n[200]\tvalid_0's binary_logloss: 0.153338\tvalid_0's gini: 0.263768\n[300]\tvalid_0's binary_logloss: 0.152804\tvalid_0's gini: 0.267635\n[400]\tvalid_0's binary_logloss: 0.152483\tvalid_0's gini: 0.271009\n[500]\tvalid_0's binary_logloss: 0.152299\tvalid_0's gini: 0.27324\n[600]\tvalid_0's binary_logloss: 0.152157\tvalid_0's gini: 0.275756\n[700]\tvalid_0's binary_logloss: 0.15206\tvalid_0's gini: 0.277655\n[800]\tvalid_0's binary_logloss: 0.151986\tvalid_0's gini: 0.279371\n[900]\tvalid_0's binary_logloss: 0.151942\tvalid_0's gini: 0.280359\n[1000]\tvalid_0's binary_logloss: 0.151898\tvalid_0's gini: 0.281475\n[1100]\tvalid_0's binary_logloss: 0.15186\tvalid_0's gini: 0.282482\n[1200]\tvalid_0's binary_logloss: 0.151835\tvalid_0's gini: 0.283198\n[1300]\tvalid_0's binary_logloss: 0.15181\tvalid_0's gini: 0.283848\n[1400]\tvalid_0's binary_logloss: 0.151796\tvalid_0's gini: 0.284221\n[1500]\tvalid_0's binary_logloss: 0.151781\tvalid_0's gini: 0.284645\n[1600]\tvalid_0's binary_logloss: 0.15177\tvalid_0's gini: 0.284943\n[1700]\tvalid_0's binary_logloss: 0.151761\tvalid_0's gini: 0.285129\n[1800]\tvalid_0's binary_logloss: 0.151755\tvalid_0's gini: 0.28522\n[1900]\tvalid_0's binary_logloss: 0.151752\tvalid_0's gini: 0.285325\n[2000]\tvalid_0's binary_logloss: 0.151749\tvalid_0's gini: 0.285504\n[2100]\tvalid_0's binary_logloss: 0.151748\tvalid_0's gini: 0.285633\n[2200]\tvalid_0's binary_logloss: 0.151744\tvalid_0's gini: 0.285711\n[2300]\tvalid_0's binary_logloss: 0.15174\tvalid_0's gini: 0.285853\n[2400]\tvalid_0's binary_logloss: 0.15174\tvalid_0's gini: 0.28594\n[2500]\tvalid_0's binary_logloss: 0.151745\tvalid_0's gini: 0.285916\nDid not meet early stopping. Best iteration is:\n[2334]\tvalid_0's binary_logloss: 0.151736\tvalid_0's gini: 0.285929\n폴드 2 지니계수: 0.2859292916021393\n\n######################################## 폴드 3 / 폴드 5 ########################################\n[LightGBM] [Info] Number of positive: 17356, number of negative: 458814\n[LightGBM] [Info] Total Bins 1558\n[LightGBM] [Info] Number of data points in the train set: 476170, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036449 -> initscore=-3.274707\n[LightGBM] [Info] Start training from score -3.274707\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.15424\tvalid_0's gini: 0.263985\n[200]\tvalid_0's binary_logloss: 0.153171\tvalid_0's gini: 0.268713\n[300]\tvalid_0's binary_logloss: 0.152574\tvalid_0's gini: 0.272773\n[400]\tvalid_0's binary_logloss: 0.152223\tvalid_0's gini: 0.275785\n[500]\tvalid_0's binary_logloss: 0.152001\tvalid_0's gini: 0.278098\n[600]\tvalid_0's binary_logloss: 0.151847\tvalid_0's gini: 0.280206\n[700]\tvalid_0's binary_logloss: 0.151748\tvalid_0's gini: 0.281603\n[800]\tvalid_0's binary_logloss: 0.151682\tvalid_0's gini: 0.282672\n[900]\tvalid_0's binary_logloss: 0.151637\tvalid_0's gini: 0.283423\n[1000]\tvalid_0's binary_logloss: 0.151608\tvalid_0's gini: 0.283963\n[1100]\tvalid_0's binary_logloss: 0.151589\tvalid_0's gini: 0.284105\n[1200]\tvalid_0's binary_logloss: 0.151574\tvalid_0's gini: 0.284387\n[1300]\tvalid_0's binary_logloss: 0.151575\tvalid_0's gini: 0.284318\n[1400]\tvalid_0's binary_logloss: 0.151572\tvalid_0's gini: 0.284372\n[1500]\tvalid_0's binary_logloss: 0.151569\tvalid_0's gini: 0.284466\n[1600]\tvalid_0's binary_logloss: 0.151574\tvalid_0's gini: 0.284435\n[1700]\tvalid_0's binary_logloss: 0.151579\tvalid_0's gini: 0.284362\nEarly stopping, best iteration is:\n[1478]\tvalid_0's binary_logloss: 0.151568\tvalid_0's gini: 0.284492\n폴드 3 지니계수: 0.2844916047790675\n\n######################################## 폴드 4 / 폴드 5 ########################################\n[LightGBM] [Info] Number of positive: 17355, number of negative: 458815\n[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476170, number of used features: 216\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274766\n[LightGBM] [Info] Start training from score -3.274766\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.154327\tvalid_0's gini: 0.256916\n[200]\tvalid_0's binary_logloss: 0.15331\tvalid_0's gini: 0.261871\n[300]\tvalid_0's binary_logloss: 0.152761\tvalid_0's gini: 0.265441\n[400]\tvalid_0's binary_logloss: 0.152441\tvalid_0's gini: 0.268613\n[500]\tvalid_0's binary_logloss: 0.152245\tvalid_0's gini: 0.271168\n[600]\tvalid_0's binary_logloss: 0.152098\tvalid_0's gini: 0.273746\n[700]\tvalid_0's binary_logloss: 0.152012\tvalid_0's gini: 0.275192\n[800]\tvalid_0's binary_logloss: 0.151952\tvalid_0's gini: 0.276278\n[900]\tvalid_0's binary_logloss: 0.151911\tvalid_0's gini: 0.277039\n[1000]\tvalid_0's binary_logloss: 0.151871\tvalid_0's gini: 0.277996\n[1100]\tvalid_0's binary_logloss: 0.151844\tvalid_0's gini: 0.278535\n[1200]\tvalid_0's binary_logloss: 0.151827\tvalid_0's gini: 0.279055\n[1300]\tvalid_0's binary_logloss: 0.151817\tvalid_0's gini: 0.27936\n[1400]\tvalid_0's binary_logloss: 0.151799\tvalid_0's gini: 0.279872\n[1500]\tvalid_0's binary_logloss: 0.151797\tvalid_0's gini: 0.280053\n[1600]\tvalid_0's binary_logloss: 0.151792\tvalid_0's gini: 0.280148\n[1700]\tvalid_0's binary_logloss: 0.151794\tvalid_0's gini: 0.280162\n[1800]\tvalid_0's binary_logloss: 0.151793\tvalid_0's gini: 0.280319\n[1900]\tvalid_0's binary_logloss: 0.151795\tvalid_0's gini: 0.280422\n[2000]\tvalid_0's binary_logloss: 0.151797\tvalid_0's gini: 0.280419\n[2100]\tvalid_0's binary_logloss: 0.151799\tvalid_0's gini: 0.280516\nEarly stopping, best iteration is:\n[1852]\tvalid_0's binary_logloss: 0.15179\tvalid_0's gini: 0.280514\n폴드 4 지니계수: 0.2805136229288192\n\n######################################## 폴드 5 / 폴드 5 ########################################\n[LightGBM] [Info] Number of positive: 17355, number of negative: 458815\n[LightGBM] [Info] Total Bins 1558\n[LightGBM] [Info] Number of data points in the train set: 476170, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274766\n[LightGBM] [Info] Start training from score -3.274766\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.15439\tvalid_0's gini: 0.26681\n[200]\tvalid_0's binary_logloss: 0.15338\tvalid_0's gini: 0.272186\n[300]\tvalid_0's binary_logloss: 0.152821\tvalid_0's gini: 0.275897\n[400]\tvalid_0's binary_logloss: 0.1525\tvalid_0's gini: 0.278734\n[500]\tvalid_0's binary_logloss: 0.152277\tvalid_0's gini: 0.282151\n[600]\tvalid_0's binary_logloss: 0.15212\tvalid_0's gini: 0.285039\n[700]\tvalid_0's binary_logloss: 0.152009\tvalid_0's gini: 0.287435\n[800]\tvalid_0's binary_logloss: 0.15192\tvalid_0's gini: 0.289549\n[900]\tvalid_0's binary_logloss: 0.151862\tvalid_0's gini: 0.290886\n[1000]\tvalid_0's binary_logloss: 0.151819\tvalid_0's gini: 0.291935\n[1100]\tvalid_0's binary_logloss: 0.151782\tvalid_0's gini: 0.292972\n[1200]\tvalid_0's binary_logloss: 0.151752\tvalid_0's gini: 0.293784\n[1300]\tvalid_0's binary_logloss: 0.151732\tvalid_0's gini: 0.294315\n[1400]\tvalid_0's binary_logloss: 0.151724\tvalid_0's gini: 0.294475\n[1500]\tvalid_0's binary_logloss: 0.151713\tvalid_0's gini: 0.294786\n[1600]\tvalid_0's binary_logloss: 0.1517\tvalid_0's gini: 0.295146\n[1700]\tvalid_0's binary_logloss: 0.151694\tvalid_0's gini: 0.295268\n[1800]\tvalid_0's binary_logloss: 0.151695\tvalid_0's gini: 0.295212\n[1900]\tvalid_0's binary_logloss: 0.151689\tvalid_0's gini: 0.295454\n[2000]\tvalid_0's binary_logloss: 0.151693\tvalid_0's gini: 0.2954\n[2100]\tvalid_0's binary_logloss: 0.151694\tvalid_0's gini: 0.295427\n[2200]\tvalid_0's binary_logloss: 0.151692\tvalid_0's gini: 0.295538\n[2300]\tvalid_0's binary_logloss: 0.151699\tvalid_0's gini: 0.295411\nEarly stopping, best iteration is:\n[2045]\tvalid_0's binary_logloss: 0.151689\tvalid_0's gini: 0.295553\n폴드 5 지니계수: 0.29555250456072807\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2.OOF 검증 데이터 지니계수","metadata":{}},{"cell_type":"code","source":"print(\"OOF 검증 데이터 지니계수:\", eval_gini(y, oof_val_preds))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T16:26:15.046298Z","iopub.execute_input":"2023-10-12T16:26:15.046671Z","iopub.status.idle":"2023-10-12T16:26:15.162334Z","shell.execute_reply.started":"2023-10-12T16:26:15.046645Z","shell.execute_reply":"2023-10-12T16:26:15.160706Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"OOF 검증 데이터 지니계수: 0.2889651000887542\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 예측 및 결과 제출","metadata":{}},{"cell_type":"code","source":"submission[\"target\"] = oof_test_preds\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T16:26:15.163905Z","iopub.execute_input":"2023-10-12T16:26:15.164206Z","iopub.status.idle":"2023-10-12T16:26:17.649030Z","shell.execute_reply.started":"2023-10-12T16:26:15.164182Z","shell.execute_reply":"2023-10-12T16:26:17.647382Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}