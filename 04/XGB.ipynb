{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 피처 엔지니어링\n## 1.데이터 합치기","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/porto-seguro-safe-driver-prediction/'\ntrain = pd.read_csv(data_path + 'train.csv', index_col=\"id\")\ntest = pd.read_csv(data_path + 'test.csv', index_col=\"id\")\nsubmission = pd.read_csv(data_path + 'sample_submission.csv', index_col=\"id\")","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:24:55.772545Z","iopub.execute_input":"2023-10-11T09:24:55.772972Z","iopub.status.idle":"2023-10-11T09:25:07.543239Z","shell.execute_reply.started":"2023-10-11T09:24:55.772935Z","shell.execute_reply":"2023-10-11T09:25:07.541921Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"all_data = pd.concat([train, test], ignore_index=True)\nall_data = all_data.drop(\"target\", axis=1) # 타깃값 제거","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:07.545270Z","iopub.execute_input":"2023-10-11T09:25:07.545599Z","iopub.status.idle":"2023-10-11T09:25:08.449798Z","shell.execute_reply.started":"2023-10-11T09:25:07.545571Z","shell.execute_reply":"2023-10-11T09:25:08.448715Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"all_features = all_data.columns # 전체 피처\nall_features","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:08.450971Z","iopub.execute_input":"2023-10-11T09:25:08.451302Z","iopub.status.idle":"2023-10-11T09:25:08.460238Z","shell.execute_reply.started":"2023-10-11T09:25:08.451275Z","shell.execute_reply":"2023-10-11T09:25:08.459026Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Index(['ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n       'ps_calc_20_bin'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2.명목형 피처 원-핫 인코딩","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncat_features = [feature for feature in all_features if \"cat\" in feature] # 명목형 피처 추출\nonehot_encoder = OneHotEncoder() # 원-핫 인코더 객체 생성\nencoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])\nencoded_cat_matrix","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:08.463767Z","iopub.execute_input":"2023-10-11T09:25:08.464220Z","iopub.status.idle":"2023-10-11T09:25:11.377971Z","shell.execute_reply.started":"2023-10-11T09:25:08.464187Z","shell.execute_reply":"2023-10-11T09:25:11.376726Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<1488028x184 sparse matrix of type '<class 'numpy.float64'>'\n\twith 20832392 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 3.파생 피처 추가","metadata":{}},{"cell_type":"code","source":"# \"데이터 하나당 결측값 개수\"를 파생 피처로 추가\nall_data[\"num_missing\"] = (all_data==-1).sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:11.380156Z","iopub.execute_input":"2023-10-11T09:25:11.380782Z","iopub.status.idle":"2023-10-11T09:25:11.814898Z","shell.execute_reply.started":"2023-10-11T09:25:11.380737Z","shell.execute_reply":"2023-10-11T09:25:11.813596Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 명목형 피처, calc 분류의 피처를 제외한 피처\nremaining_features = [feature for feature in all_features \n                      if (\"cat\" not in feature and \"calc\" not in feature)]\n# num_missing을 remaining_features에 추가\nremaining_features.append(\"num_missing\")","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:11.816329Z","iopub.execute_input":"2023-10-11T09:25:11.816663Z","iopub.status.idle":"2023-10-11T09:25:11.821730Z","shell.execute_reply.started":"2023-10-11T09:25:11.816634Z","shell.execute_reply":"2023-10-11T09:25:11.820761Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 분류가 ind인 피처\nind_features = [feature for feature in all_features if \"ind\" in feature]\nis_first_feature = True\n\nfor ind_feature in ind_features:\n    if is_first_feature:\n        all_data[\"mix_ind\"] = all_data[ind_feature].astype(str) + \"_\"\n        is_first_feature = False\n    else:\n        all_data[\"mix_ind\"] += all_data[ind_feature].astype(str) + \"_\"","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:11.823002Z","iopub.execute_input":"2023-10-11T09:25:11.823946Z","iopub.status.idle":"2023-10-11T09:25:31.412645Z","shell.execute_reply.started":"2023-10-11T09:25:11.823915Z","shell.execute_reply":"2023-10-11T09:25:31.411528Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 명목형 피처의 고윳값별 개수\ncat_count_features = []\n\nfor feature in cat_features+[\"mix_ind\"]:\n    val_counts_dict = all_data[feature].value_counts().to_dict()\n    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x:val_counts_dict[x])\n    cat_count_features.append(f'{feature}_count')\ncat_count_features","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:31.413893Z","iopub.execute_input":"2023-10-11T09:25:31.414966Z","iopub.status.idle":"2023-10-11T09:25:40.676072Z","shell.execute_reply.started":"2023-10-11T09:25:31.414928Z","shell.execute_reply":"2023-10-11T09:25:40.674800Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['ps_ind_02_cat_count',\n 'ps_ind_04_cat_count',\n 'ps_ind_05_cat_count',\n 'ps_car_01_cat_count',\n 'ps_car_02_cat_count',\n 'ps_car_03_cat_count',\n 'ps_car_04_cat_count',\n 'ps_car_05_cat_count',\n 'ps_car_06_cat_count',\n 'ps_car_07_cat_count',\n 'ps_car_08_cat_count',\n 'ps_car_09_cat_count',\n 'ps_car_10_cat_count',\n 'ps_car_11_cat_count',\n 'mix_ind_count']"},"metadata":{}}]},{"cell_type":"markdown","source":"## 4.필요 없는 피처 제거","metadata":{}},{"cell_type":"code","source":"from scipy import sparse\n\n# 필요 없는 피처들 제거\ndrop_features = [\"ps_ind_14\", \"ps_ind_10_bin\", \"ps_ind_11_bin\", \"ps_ind_12_bin\", \"ps_ind_13_bin\", \"ps_car_14\"]\n# remaining_features, cat_count_features에서 drop_features를 제거한 데이터\nall_data_remaining = all_data[remaining_features+cat_count_features].drop(drop_features, axis=1)\n# 데이터 합치기\nall_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining), encoded_cat_matrix], format=\"csr\")","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:40.680396Z","iopub.execute_input":"2023-10-11T09:25:40.680774Z","iopub.status.idle":"2023-10-11T09:25:45.894744Z","shell.execute_reply.started":"2023-10-11T09:25:40.680745Z","shell.execute_reply":"2023-10-11T09:25:45.893783Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 5.데이터 나누기","metadata":{}},{"cell_type":"code","source":"num_train = len(train)\nX = all_data_sprs[:num_train]\nX_test = all_data_sprs[num_train:]\ny = train[\"target\"].values","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:45.897973Z","iopub.execute_input":"2023-10-11T09:25:45.898350Z","iopub.status.idle":"2023-10-11T09:25:47.152629Z","shell.execute_reply.started":"2023-10-11T09:25:45.898318Z","shell.execute_reply":"2023-10-11T09:25:47.151626Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 평가지표 계산 함수 작성\n## 1.정규화된 지니계수 계산 함수","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef eval_gini(y_true, y_pred):\n    assert y_true.shape == y_pred.shape\n    n_samples = y_true.shape[0] # 데이터 개수\n    L_mid = np.linspace(1/n_samples, 1, n_samples) # 대각선 값\n    \n    # 1) 예측값에 대한 지니계수\n    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로, y_true 값 정렬\n    L_pred = np.cumsum(pred_order)/np.sum(pred_order) # 로렌츠 곡선\n    G_pred = np.sum(L_mid - L_pred) # 예측값에 대한 지니계수\n    # 2) 예측이 완벽할 때 지니계수\n    true_order = y_true[y_true.argsort()] # y_true 크기순으로, y_true 값 정렬\n    L_true = np.cumsum(true_order)/np.sum(true_order) # 로렌츠 곡선\n    G_true = np.sum(L_mid - L_true) # 예측이 완벽할 때 지니계수\n    # 3) 정규화된 지니계수\n    return G_pred/G_true","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:47.153964Z","iopub.execute_input":"2023-10-11T09:25:47.155010Z","iopub.status.idle":"2023-10-11T09:25:47.163904Z","shell.execute_reply.started":"2023-10-11T09:25:47.154946Z","shell.execute_reply":"2023-10-11T09:25:47.162306Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 2.XGBoost용 지니계수","metadata":{}},{"cell_type":"code","source":"def gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return \"gini\", eval_gini(labels, preds) # 반환값","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:47.166227Z","iopub.execute_input":"2023-10-11T09:25:47.166686Z","iopub.status.idle":"2023-10-11T09:25:47.177846Z","shell.execute_reply.started":"2023-10-11T09:25:47.166643Z","shell.execute_reply":"2023-10-11T09:25:47.176734Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# 하이퍼파라미터 최적화\n## 1.데이터셋 준비","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\nbayes_dtrain = xgb.DMatrix(X_train, y_train)\nbayes_dvalid = xgb.DMatrix(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:47.179361Z","iopub.execute_input":"2023-10-11T09:25:47.179799Z","iopub.status.idle":"2023-10-11T09:25:48.083974Z","shell.execute_reply.started":"2023-10-11T09:25:47.179764Z","shell.execute_reply":"2023-10-11T09:25:48.082905Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## 2.하이퍼파라미터 범위 설정","metadata":{}},{"cell_type":"code","source":"# 베이지안 최적화를 위한 하이퍼파라미터 범위\nparam_bounds = {\"max_depth\": (4, 8),\n                \"subsample\": (0.6, 0.9),\n                \"colsample_bytree\": (0.7, 1.0),\n                \"min_child_weight\": (5, 7),\n                \"gamma\": (8, 11),\n                \"reg_alpha\": (7, 9),\n                \"reg_lambda\": (1.1, 1.5),\n                \"scale_pos_weight\": (1.4, 1.6)}\n\n# 값이 고정된 하이퍼파라미터\nfixed_params = {\"objective\": \"binary:logistic\",\n                \"learning_rate\": 0.02,\n                \"random_state\": 1991}","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:48.085783Z","iopub.execute_input":"2023-10-11T09:25:48.086555Z","iopub.status.idle":"2023-10-11T09:25:48.092479Z","shell.execute_reply.started":"2023-10-11T09:25:48.086514Z","shell.execute_reply":"2023-10-11T09:25:48.091549Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## 3.(베이지안 최적화용) 평가지표 계산함수 작성","metadata":{}},{"cell_type":"code","source":"def eval_function(max_depth, subsample, colsample_bytree, min_child_weight, \n                  reg_alpha, gamma, reg_lambda, scale_pos_weight):\n    '''최적화하려는 평가지표(지니계수) 계산 함수'''\n    # 베이지안 최적화를 수행할 하이퍼파라미터\n    params = {\"max_depth\": int(round(max_depth)),\n              \"subsample\": subsample,\n              \"colsample_bytree\": colsample_bytree,\n              \"min_child_weight\": min_child_weight,\n              \"gamma\": gamma,\n              \"reg_alpha\": reg_alpha,\n              \"reg_lambda\": reg_lambda,\n              \"scale_pos_weight\": scale_pos_weight}\n    params.update(fixed_params) # 고정된 하이퍼파라미터도 추가\n    print(\"하이퍼파라미터:\", params)\n    \n    # XGBoost 모델 훈련\n    xgb_model = xgb.train(params=params,\n                          dtrain=bayes_dtrain,\n                          num_boost_round=2500,\n                          evals=[(bayes_dvalid, \"bayes_dvalid\")],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=False)\n    best_iter = xgb_model.best_iteration # 최적 반복 횟수\n    preds = xgb_model.predict(bayes_dvalid, iteration_range=(0, best_iter)) # 검증 데이터로 예측 수행\n    gini_score = eval_gini(y_valid, preds) # 지니계수 계산\n    print(f'지니계수: {gini_score}\\n')\n    \n    return gini_score","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:48.094502Z","iopub.execute_input":"2023-10-11T09:25:48.095463Z","iopub.status.idle":"2023-10-11T09:25:48.218014Z","shell.execute_reply.started":"2023-10-11T09:25:48.095405Z","shell.execute_reply":"2023-10-11T09:25:48.217122Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## 4.최적화 수행","metadata":{}},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\n# 베이지안 최적화 객체 생성\noptimizer = BayesianOptimization(f=eval_function, pbounds=param_bounds, random_state=0)\n# 베이지안 최적화 수행\noptimizer.maximize(init_points=3, n_iter=6)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:25:48.220087Z","iopub.execute_input":"2023-10-11T09:25:48.221144Z","iopub.status.idle":"2023-10-11T12:25:01.515006Z","shell.execute_reply.started":"2023-10-11T09:25:48.221082Z","shell.execute_reply":"2023-10-11T12:25:01.513656Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | reg_alpha | reg_la... | scale_... | subsample |\n-------------------------------------------------------------------------------------------------------------------------\n하이퍼파라미터: {'max_depth': 6, 'subsample': 0.867531900234624, 'colsample_bytree': 0.8646440511781974, 'min_child_weight': 6.0897663659937935, 'gamma': 10.14556809911726, 'reg_alpha': 7.84730959867781, 'reg_lambda': 1.3583576452266626, 'scale_pos_weight': 1.4875174422525386, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"지니계수: 0.28470429444834217\n\n| \u001b[0m1        \u001b[0m | \u001b[0m0.2847   \u001b[0m | \u001b[0m0.8646   \u001b[0m | \u001b[0m10.15    \u001b[0m | \u001b[0m6.411    \u001b[0m | \u001b[0m6.09     \u001b[0m | \u001b[0m7.847    \u001b[0m | \u001b[0m1.358    \u001b[0m | \u001b[0m1.488    \u001b[0m | \u001b[0m0.8675   \u001b[0m |\n하이퍼파라미터: {'max_depth': 7, 'subsample': 0.6261387899104622, 'colsample_bytree': 0.9890988281503088, 'min_child_weight': 6.0577898395058085, 'gamma': 9.150324556477333, 'reg_alpha': 8.136089122187865, 'reg_lambda': 1.4702386553170643, 'scale_pos_weight': 1.4142072116395774, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n지니계수: 0.28502030930848077\n\n| \u001b[95m2        \u001b[0m | \u001b[95m0.285    \u001b[0m | \u001b[95m0.9891   \u001b[0m | \u001b[95m9.15     \u001b[0m | \u001b[95m7.167    \u001b[0m | \u001b[95m6.058    \u001b[0m | \u001b[95m8.136    \u001b[0m | \u001b[95m1.47     \u001b[0m | \u001b[95m1.414    \u001b[0m | \u001b[95m0.6261   \u001b[0m |\n하이퍼파라미터: {'max_depth': 7, 'subsample': 0.8341587528859367, 'colsample_bytree': 0.7060655192320977, 'min_child_weight': 6.7400242964936385, 'gamma': 10.497859536643814, 'reg_alpha': 8.957236684465528, 'reg_lambda': 1.4196634256866894, 'scale_pos_weight': 1.4922958724505864, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n지니계수: 0.28504876002702845\n\n| \u001b[95m3        \u001b[0m | \u001b[95m0.285    \u001b[0m | \u001b[95m0.7061   \u001b[0m | \u001b[95m10.5     \u001b[0m | \u001b[95m7.113    \u001b[0m | \u001b[95m6.74     \u001b[0m | \u001b[95m8.957    \u001b[0m | \u001b[95m1.42     \u001b[0m | \u001b[95m1.492    \u001b[0m | \u001b[95m0.8342   \u001b[0m |\n하이퍼파라미터: {'max_depth': 7, 'subsample': 0.7001630536555632, 'colsample_bytree': 0.8843124587484356, 'min_child_weight': 6.494091293383359, 'gamma': 10.452246227672624, 'reg_alpha': 8.551838810159788, 'reg_lambda': 1.3814765995549108, 'scale_pos_weight': 1.423280772455086, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"지니계수: 0.28409091782139356\n\n| \u001b[0m4        \u001b[0m | \u001b[0m0.2841   \u001b[0m | \u001b[0m0.8843   \u001b[0m | \u001b[0m10.45    \u001b[0m | \u001b[0m6.838    \u001b[0m | \u001b[0m6.494    \u001b[0m | \u001b[0m8.552    \u001b[0m | \u001b[0m1.381    \u001b[0m | \u001b[0m1.423    \u001b[0m | \u001b[0m0.7002   \u001b[0m |\n하이퍼파라미터: {'max_depth': 7, 'subsample': 0.8535233675350644, 'colsample_bytree': 0.92975858050776, 'min_child_weight': 6.249564429359247, 'gamma': 9.95563546750357, 'reg_alpha': 8.411512219837842, 'reg_lambda': 1.424460008293778, 'scale_pos_weight': 1.5416807226581535, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"지니계수: 0.2856515869205076\n\n| \u001b[95m5        \u001b[0m | \u001b[95m0.2857   \u001b[0m | \u001b[95m0.9298   \u001b[0m | \u001b[95m9.956    \u001b[0m | \u001b[95m6.809    \u001b[0m | \u001b[95m6.25     \u001b[0m | \u001b[95m8.412    \u001b[0m | \u001b[95m1.424    \u001b[0m | \u001b[95m1.542    \u001b[0m | \u001b[95m0.8535   \u001b[0m |\n하이퍼파라미터: {'max_depth': 7, 'subsample': 0.6462619019069298, 'colsample_bytree': 0.80929192865947, 'min_child_weight': 6.079999276892042, 'gamma': 9.553916776586505, 'reg_alpha': 8.860396362258099, 'reg_lambda': 1.4050740023119348, 'scale_pos_weight': 1.4668544695338273, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"지니계수: 0.28475802570872605\n\n| \u001b[0m6        \u001b[0m | \u001b[0m0.2848   \u001b[0m | \u001b[0m0.8093   \u001b[0m | \u001b[0m9.554    \u001b[0m | \u001b[0m6.532    \u001b[0m | \u001b[0m6.08     \u001b[0m | \u001b[0m8.86     \u001b[0m | \u001b[0m1.405    \u001b[0m | \u001b[0m1.467    \u001b[0m | \u001b[0m0.6463   \u001b[0m |\n하이퍼파라미터: {'max_depth': 7, 'subsample': 0.6931141936797243, 'colsample_bytree': 0.8817801730078565, 'min_child_weight': 6.992334203641873, 'gamma': 9.013424730095146, 'reg_alpha': 7.640858389939128, 'reg_lambda': 1.3562805915715632, 'scale_pos_weight': 1.449446257931491, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"지니계수: 0.2864072333145655\n\n| \u001b[95m7        \u001b[0m | \u001b[95m0.2864   \u001b[0m | \u001b[95m0.8818   \u001b[0m | \u001b[95m9.013    \u001b[0m | \u001b[95m6.927    \u001b[0m | \u001b[95m6.992    \u001b[0m | \u001b[95m7.641    \u001b[0m | \u001b[95m1.356    \u001b[0m | \u001b[95m1.449    \u001b[0m | \u001b[95m0.6931   \u001b[0m |\n하이퍼파라미터: {'max_depth': 5, 'subsample': 0.6261564417044092, 'colsample_bytree': 0.8763145220620449, 'min_child_weight': 5.135323353557588, 'gamma': 8.39495450163982, 'reg_alpha': 8.950443047087845, 'reg_lambda': 1.4235649099168255, 'scale_pos_weight': 1.5217625173811569, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"지니계수: 0.2840512946560939\n\n| \u001b[0m8        \u001b[0m | \u001b[0m0.2841   \u001b[0m | \u001b[0m0.8763   \u001b[0m | \u001b[0m8.395    \u001b[0m | \u001b[0m4.561    \u001b[0m | \u001b[0m5.135    \u001b[0m | \u001b[0m8.95     \u001b[0m | \u001b[0m1.424    \u001b[0m | \u001b[0m1.522    \u001b[0m | \u001b[0m0.6262   \u001b[0m |\n하이퍼파라미터: {'max_depth': 6, 'subsample': 0.857971740304964, 'colsample_bytree': 0.9583821245229369, 'min_child_weight': 6.158305055403563, 'gamma': 9.305332775334449, 'reg_alpha': 8.200928434091152, 'reg_lambda': 1.2571039588093065, 'scale_pos_weight': 1.4700266933495618, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"지니계수: 0.2850853383669918\n\n| \u001b[0m9        \u001b[0m | \u001b[0m0.2851   \u001b[0m | \u001b[0m0.9584   \u001b[0m | \u001b[0m9.305    \u001b[0m | \u001b[0m5.594    \u001b[0m | \u001b[0m6.158    \u001b[0m | \u001b[0m8.201    \u001b[0m | \u001b[0m1.257    \u001b[0m | \u001b[0m1.47     \u001b[0m | \u001b[0m0.858    \u001b[0m |\n=========================================================================================================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 5.결과 확인","metadata":{}},{"cell_type":"code","source":"# 평가함수 점수가 최대일 때 하이퍼파라미터\nmax_params = optimizer.max[\"params\"]\nmax_params","metadata":{"execution":{"iopub.status.busy":"2023-10-11T12:25:01.516631Z","iopub.execute_input":"2023-10-11T12:25:01.516996Z","iopub.status.idle":"2023-10-11T12:25:01.526567Z","shell.execute_reply.started":"2023-10-11T12:25:01.516960Z","shell.execute_reply":"2023-10-11T12:25:01.525477Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'colsample_bytree': 0.8817801730078565,\n 'gamma': 9.013424730095146,\n 'max_depth': 6.927417000715145,\n 'min_child_weight': 6.992334203641873,\n 'reg_alpha': 7.640858389939128,\n 'reg_lambda': 1.3562805915715632,\n 'scale_pos_weight': 1.449446257931491,\n 'subsample': 0.6931141936797243}"},"metadata":{}}]},{"cell_type":"code","source":"# 정수형 하이퍼파라미터 변환\nmax_params[\"max_depth\"] = int(round(max_params[\"max_depth\"]))\n# 값이 고정된 하이퍼파라미터 추가\nmax_params.update(fixed_params)\nmax_params","metadata":{"execution":{"iopub.status.busy":"2023-10-11T12:25:01.528471Z","iopub.execute_input":"2023-10-11T12:25:01.529017Z","iopub.status.idle":"2023-10-11T12:25:01.541509Z","shell.execute_reply.started":"2023-10-11T12:25:01.528945Z","shell.execute_reply":"2023-10-11T12:25:01.540196Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'colsample_bytree': 0.8817801730078565,\n 'gamma': 9.013424730095146,\n 'max_depth': 7,\n 'min_child_weight': 6.992334203641873,\n 'reg_alpha': 7.640858389939128,\n 'reg_lambda': 1.3562805915715632,\n 'scale_pos_weight': 1.449446257931491,\n 'subsample': 0.6931141936797243,\n 'objective': 'binary:logistic',\n 'learning_rate': 0.02,\n 'random_state': 1991}"},"metadata":{}}]},{"cell_type":"markdown","source":"# 모델 훈련 및 성능 검증\n## 1.최적 하이퍼파라미터를 이용해 XGBoost 훈련","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\n# 층화 K 폴드 교차 검증기\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n# OOF 방식으로 훈련된 모델로, 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_val_preds = np.zeros(X.shape[0])\n# OOF 방식으로 훈련된 모델로, 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_test_preds = np.zeros(X_test.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-10-11T12:25:01.542454Z","iopub.execute_input":"2023-10-11T12:25:01.542741Z","iopub.status.idle":"2023-10-11T12:25:01.561904Z","shell.execute_reply.started":"2023-10-11T12:25:01.542716Z","shell.execute_reply":"2023-10-11T12:25:01.560628Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# OOF 방식으로 모델 훈련, 검증, 예측\nfor idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40) # 각 폴드를 구분하는 문구 출력\n\n    X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n    X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n    dtrain = xgb.DMatrix(X_train, y_train)        # XGBoost 전용 훈련 데이터\n    dvalid = xgb.DMatrix(X_valid, y_valid)        # XGBoost 전용 검증 데이터\n    dtest  = xgb.DMatrix(X_test)                  # XGBoost 전용 테스트 데이터\n\n    # XGBoost 모델 훈련\n    xgb_model = xgb.train(params=max_params, \n                          dtrain=dtrain,\n                          num_boost_round=2000,\n                          evals=[(dvalid, \"valid\")],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=100)\n    \n    # 모델 성능이 가장 좋을 때의 부스팅 반복 횟수 저장\n    best_iter = xgb_model.best_iteration\n    # 테스트 데이터를 활용해 OOF 예측\n    oof_test_preds += xgb_model.predict(dtest, iteration_range=(0, best_iter))/folds.n_splits\n    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n    oof_val_preds[valid_idx] += xgb_model.predict(dvalid, iteration_range=(0, best_iter))\n    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n    print(f'폴드 {idx+1} 지니계수: {gini_score}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-10-11T12:25:01.563534Z","iopub.execute_input":"2023-10-11T12:25:01.564500Z","iopub.status.idle":"2023-10-11T13:47:10.616940Z","shell.execute_reply.started":"2023-10-11T12:25:01.564460Z","shell.execute_reply":"2023-10-11T13:47:10.613845Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"######################################## 폴드 1 / 폴드 5 ########################################\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalid-logloss:0.67669\tvalid-gini:0.15993\n[100]\tvalid-logloss:0.19137\tvalid-gini:0.25223\n[200]\tvalid-logloss:0.15806\tvalid-gini:0.27838\n[300]\tvalid-logloss:0.15480\tvalid-gini:0.28841\n[400]\tvalid-logloss:0.15427\tvalid-gini:0.29312\n[500]\tvalid-logloss:0.15413\tvalid-gini:0.29557\n[600]\tvalid-logloss:0.15408\tvalid-gini:0.29677\n[700]\tvalid-logloss:0.15402\tvalid-gini:0.29821\n[800]\tvalid-logloss:0.15402\tvalid-gini:0.29871\n[900]\tvalid-logloss:0.15398\tvalid-gini:0.29901\n[1000]\tvalid-logloss:0.15398\tvalid-gini:0.29908\n[1100]\tvalid-logloss:0.15397\tvalid-gini:0.29906\n[1200]\tvalid-logloss:0.15396\tvalid-gini:0.29903\n[1300]\tvalid-logloss:0.15396\tvalid-gini:0.29874\n[1341]\tvalid-logloss:0.15397\tvalid-gini:0.29868\n폴드 1 지니계수: 0.299375446272267\n\n######################################## 폴드 2 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67669\tvalid-gini:0.12436\n[100]\tvalid-logloss:0.19152\tvalid-gini:0.23846\n[200]\tvalid-logloss:0.15831\tvalid-gini:0.26558\n[300]\tvalid-logloss:0.15515\tvalid-gini:0.27483\n[400]\tvalid-logloss:0.15466\tvalid-gini:0.27957\n[500]\tvalid-logloss:0.15453\tvalid-gini:0.28181\n[600]\tvalid-logloss:0.15448\tvalid-gini:0.28328\n[700]\tvalid-logloss:0.15446\tvalid-gini:0.28443\n[800]\tvalid-logloss:0.15445\tvalid-gini:0.28485\n[900]\tvalid-logloss:0.15443\tvalid-gini:0.28503\n[1000]\tvalid-logloss:0.15442\tvalid-gini:0.28530\n[1100]\tvalid-logloss:0.15443\tvalid-gini:0.28519\n[1200]\tvalid-logloss:0.15444\tvalid-gini:0.28502\n[1270]\tvalid-logloss:0.15443\tvalid-gini:0.28509\n폴드 2 지니계수: 0.28542783355302637\n\n######################################## 폴드 3 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67668\tvalid-gini:0.15686\n[100]\tvalid-logloss:0.19140\tvalid-gini:0.24718\n[200]\tvalid-logloss:0.15806\tvalid-gini:0.27208\n[300]\tvalid-logloss:0.15483\tvalid-gini:0.28011\n[400]\tvalid-logloss:0.15434\tvalid-gini:0.28345\n[500]\tvalid-logloss:0.15426\tvalid-gini:0.28436\n[600]\tvalid-logloss:0.15424\tvalid-gini:0.28486\n[700]\tvalid-logloss:0.15421\tvalid-gini:0.28509\n[800]\tvalid-logloss:0.15421\tvalid-gini:0.28494\n[900]\tvalid-logloss:0.15422\tvalid-gini:0.28482\n[915]\tvalid-logloss:0.15422\tvalid-gini:0.28473\n폴드 3 지니계수: 0.2852681058005433\n\n######################################## 폴드 4 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67667\tvalid-gini:0.17025\n[100]\tvalid-logloss:0.19134\tvalid-gini:0.23918\n[200]\tvalid-logloss:0.15817\tvalid-gini:0.26521\n[300]\tvalid-logloss:0.15504\tvalid-gini:0.27259\n[400]\tvalid-logloss:0.15459\tvalid-gini:0.27553\n[500]\tvalid-logloss:0.15449\tvalid-gini:0.27715\n[600]\tvalid-logloss:0.15444\tvalid-gini:0.27875\n[700]\tvalid-logloss:0.15442\tvalid-gini:0.27888\n[800]\tvalid-logloss:0.15442\tvalid-gini:0.27911\n[900]\tvalid-logloss:0.15441\tvalid-gini:0.27894\n[998]\tvalid-logloss:0.15442\tvalid-gini:0.27874\n폴드 4 지니계수: 0.2790999898036216\n\n######################################## 폴드 5 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67669\tvalid-gini:0.17093\n[100]\tvalid-logloss:0.19143\tvalid-gini:0.25033\n[200]\tvalid-logloss:0.15830\tvalid-gini:0.27389\n[300]\tvalid-logloss:0.15508\tvalid-gini:0.28460\n[400]\tvalid-logloss:0.15457\tvalid-gini:0.28931\n[500]\tvalid-logloss:0.15443\tvalid-gini:0.29169\n[600]\tvalid-logloss:0.15438\tvalid-gini:0.29312\n[700]\tvalid-logloss:0.15431\tvalid-gini:0.29450\n[800]\tvalid-logloss:0.15429\tvalid-gini:0.29541\n[900]\tvalid-logloss:0.15425\tvalid-gini:0.29570\n[1000]\tvalid-logloss:0.15424\tvalid-gini:0.29613\n[1100]\tvalid-logloss:0.15425\tvalid-gini:0.29629\n[1200]\tvalid-logloss:0.15421\tvalid-gini:0.29681\n[1300]\tvalid-logloss:0.15421\tvalid-gini:0.29648\n[1400]\tvalid-logloss:0.15423\tvalid-gini:0.29609\n[1407]\tvalid-logloss:0.15423\tvalid-gini:0.29599\n폴드 5 지니계수: 0.2968707341268111\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2.OOF 검증 데이터 지니계수","metadata":{}},{"cell_type":"code","source":"print(\"OOF 검증 데이터 지니계수:\", eval_gini(y, oof_val_preds))","metadata":{"execution":{"iopub.status.busy":"2023-10-11T13:47:10.621457Z","iopub.execute_input":"2023-10-11T13:47:10.622151Z","iopub.status.idle":"2023-10-11T13:47:10.755822Z","shell.execute_reply.started":"2023-10-11T13:47:10.622073Z","shell.execute_reply":"2023-10-11T13:47:10.754502Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"OOF 검증 데이터 지니계수: 0.2891514695415448\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 예측 및 결과 제출","metadata":{}},{"cell_type":"code","source":"submission[\"target\"] = oof_test_preds\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-11T13:47:10.757560Z","iopub.execute_input":"2023-10-11T13:47:10.758194Z","iopub.status.idle":"2023-10-11T13:47:13.279482Z","shell.execute_reply.started":"2023-10-11T13:47:10.758157Z","shell.execute_reply":"2023-10-11T13:47:13.278282Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}